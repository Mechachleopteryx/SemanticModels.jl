{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trace Generation and Modeling\n",
    "\n",
    "To test our DeepValidate approach we generate a dataset of test traces from a chain of relatively simple arithmetical functions operating on a series of randomized inputs. Given the generated program traces, we train a LSTM classifier to predict whether the output will be valid or result in an error. \n",
    "\n",
    "The trace generation is performed by `output_trace.jl` which reproduces much of the functionality of `varextract.jl` with some important differences. Rather than send trace information to `stdout`, we direct the traces to a file `traces.dat`. \n",
    "\n",
    "(It must be noted that this is not possible within an IJulia notebook due to restrictions on [task switching in staged functions](https://github.com/JuliaLang/julia/issues/18568) which prevents the trace outputs from being written to a file recursively. However, this works just fine from the command line.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function Cassette.overdub(ctx::TraceCtx,\n",
    "                          f,\n",
    "                          args...)\n",
    "    open(\"traces.dat\", \"a\") do file\n",
    "        write(file, string(f))\n",
    "        write(file, string(args))\n",
    "    end\n",
    "    \n",
    "    # if we are supposed to descend, we call Cassette.recurse\n",
    "    if Cassette.canrecurse(ctx, f, args...)\n",
    "        subtrace = (Any[],Any[])\n",
    "        push!(ctx.metadata[1], (f, args) => subtrace)\n",
    "        newctx = Cassette.similarcontext(ctx, metadata = subtrace)\n",
    "        retval = Cassette.recurse(newctx, f, args...)\n",
    "        # push!(ctx.metadata[2], subtrace[2])\n",
    "    else\n",
    "        retval = Cassette.fallback(ctx, f, args...)\n",
    "        push!(ctx.metadata[1], :t)\n",
    "        push!(ctx.metadata[2], retval)\n",
    "    end\n",
    "    @info \"returning\"\n",
    "    @show retval\n",
    "    return retval\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then modify our `@textset` so that it creates the `traces.dat` file and then loops through a large number of randomized runs of our arithmetic tests. Error conditions happen most often when our inputs are sufficiently close to zero, so a Normal(0,2) distribution gives us a good range of values to generate a reasonable percentage of \"bad\" traces on which to train. Empirically the share of \"bad\" traces generated is about 15-17%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@testset \"TraceExtract\" begin\n",
    "    g(x) = begin\n",
    "        y = add(x.*x, -x)\n",
    "        z = 1\n",
    "        v = y .- z\n",
    "        s = sum(v)\n",
    "        return s\n",
    "    end\n",
    "    h(x) = begin\n",
    "        z = g(x)\n",
    "        zed = sqrt(z)\n",
    "        return zed\n",
    "    end\n",
    "\n",
    "    open(\"traces.dat\", \"w\") do f\n",
    "        write(f, \"\")\n",
    "    end\n",
    "\n",
    "    seeds = rand(Normal(0,2),30000,3)\n",
    "    \n",
    "    for i=1:size(seeds,1)\n",
    "        ctx = TraceCtx(pass=ExtractPass, metadata = (Any[], Any[]))\n",
    "        try\n",
    "            result = Cassette.overdub(ctx, h, seeds[i,:])\n",
    "        catch DomainError\n",
    "            dump(ctx.metadata)\n",
    "        finally\n",
    "            open(\"traces.dat\", \"a\") do f\n",
    "                write(f, \"\\n\")\n",
    "            end\n",
    "        end\n",
    "        if i%1000 == 0\n",
    "            @info string(i)\n",
    "        end\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generating our raw traces, a small amount of pre-processing is required before attempting to model around them. First, we classify our \"good\" and \"bad\" traces based on whether they have resulted in an error. \n",
    "\n",
    "We then need to strip out the actual error dump information from our \"bad\" traces, as this would too easily give away the prediction game. All traces end just before they would error, allowing the validation model to predict the that next outcome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = split(String(read(\"traces.dat\")), \"\\n\");\n",
    "Ys = Int.(occursin.(Ref(r\"(Base[\\S(?!\\))]+error)\"i), text));\n",
    "\n",
    "text = split.(text, Ref(r\"(Base[\\S(?!\\))]+error)\"i));\n",
    "text = [t[1] for t in text];\n",
    "\n",
    "sum(Ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we save our traces and our labels our as CSV files for easy ingestion for our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writedlm( \"traces.csv\",  text[1:end-1], ',')\n",
    "writedlm( \"y_results.csv\",  Ys[1:end-1], ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Classifier Model\n",
    "For our modeling, we use [Flux.jl](https://github.com/FluxML/Flux.jl) and train an LSTM encoder/decoder classifier on our traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[2K\u001b[?25h\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/Uncurated`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/Uncurated.git`\n",
      "\u001b[2K\u001b[?25h\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.0/Project.toml`\n",
      " \u001b[90m [587475ba]\u001b[39m\u001b[92m + Flux v0.7.3\u001b[39m\n",
      " \u001b[90m [9920b226]\u001b[39m\u001b[92m + MLDataPattern v0.5.0\u001b[39m\n",
      " \u001b[90m [8bb1440f]\u001b[39m\u001b[92m + DelimitedFiles \u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.0/Manifest.toml`\n",
      " \u001b[90m [9920b226]\u001b[39m\u001b[92m + MLDataPattern v0.5.0\u001b[39m\n",
      " \u001b[90m [66a33bbf]\u001b[39m\u001b[92m + MLLabelUtils v0.5.1\u001b[39m\n",
      " \u001b[90m [dbb5928d]\u001b[39m\u001b[92m + MappedArrays v0.2.1\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "Pkg.add([\"Flux\", \"MLDataPattern\", \"DelimitedFiles\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_data (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DelimitedFiles\n",
    "using Flux\n",
    "using Flux: onehot, throttle, crossentropy, onehotbatch, params, shuffle\n",
    "using MLDataPattern: stratifiedobs\n",
    "using Base.Iterators: partition\n",
    "\n",
    "include(\"../../src/validation/utils.jl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58-element Array{Char,1}:\n",
       " 'g' \n",
       " 'e' \n",
       " 't' \n",
       " 'f' \n",
       " 'i' \n",
       " 'l' \n",
       " 'd' \n",
       " '(' \n",
       " 'M' \n",
       " 'a' \n",
       " 'n' \n",
       " ',' \n",
       " ' ' \n",
       " â‹®   \n",
       " 'A' \n",
       " '3' \n",
       " '6' \n",
       " '+' \n",
       " 'q' \n",
       " 'v' \n",
       " 'F' \n",
       " '<' \n",
       " '_' \n",
       " 'w' \n",
       " 'x' \n",
       " '\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Set up inputs for model\n",
    "#\n",
    "\n",
    "# Read lines from traces.dat text in to arrays of characters\n",
    "# Convert to onehot matrices\n",
    "\n",
    "cd(@__DIR__)\n",
    "\n",
    "text, alphabet, N = get_data(\"traces.dat\")\n",
    "stop = onehot('\\n', alphabet);\n",
    "alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition into subsequences to input to our model\n",
    "\n",
    "seq_len = 50\n",
    "\n",
    "Xs = [collect(partition(t,seq_len)) for t in text];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32-element Array{String,1}:\n",
       " \"getfield(Main, Symbol(\\\"#h#9\\\")){getfield(Main, Symb\"  \n",
       " \"ol(\\\"#g#8\\\"))}(getfield(Main, Symbol(\\\"#g#8\\\"))())([0.\"\n",
       " \"842063, -1.67386, 2.31813],)getfield(getfield(Main\"    \n",
       " \", Symbol(\\\"#h#9\\\")){getfield(Main, Symbol(\\\"#g#8\\\"))}(\"\n",
       " \"getfield(Main, Symbol(\\\"#g#8\\\"))()), :g)getfield(Mai\"  \n",
       " \"n, Symbol(\\\"#g#8\\\"))()([0.842063, -1.67386, 2.31813]\"  \n",
       " \",)Base.Broadcast.broadcasted(*, [0.842063, -1.6738\"    \n",
       " \"6, 2.31813], [0.842063, -1.67386, 2.31813])Base.Br\"    \n",
       " \"oadcast.materialize(Base.Broadcast.Broadcasted(*, \"    \n",
       " \"([0.842063, -1.67386, 2.31813], [0.842063, -1.6738\"    \n",
       " \"6, 2.31813])),)Base.Broadcast.instantiate(Base.Bro\"    \n",
       " \"adcast.Broadcasted(*, ([0.842063, -1.67386, 2.3181\"    \n",
       " \"3], [0.842063, -1.67386, 2.31813])),)copy(Base.Bro\"    \n",
       " â‹®                                                       \n",
       " \"e.Broadcast.materialize(Base.Broadcast.Broadcasted\"    \n",
       " \"(-, ([-0.132993, 4.47568, 3.0556], 1)),)Base.Broad\"    \n",
       " \"cast.instantiate(Base.Broadcast.Broadcasted(-, ([-\"    \n",
       " \"0.132993, 4.47568, 3.0556], 1)),)copy(Base.Broadca\"    \n",
       " \"st.Broadcasted{Base.Broadcast.DefaultArrayStyle{1}\"    \n",
       " \"}(-, ([-0.132993, 4.47568, 3.0556], 1)),)sum([-1.1\"    \n",
       " \"3299, 3.47568, 2.0556],)sqrt(4.398281802099419,)ze\"    \n",
       " \"ro(4.398281802099419,)oftype(4.398281802099419, 0)\"    \n",
       " \"typeof(4.398281802099419,)convert(Float64, 0)Float\"    \n",
       " \"64(0,)sitofp(Float64, 0)<(4.398281802099419, 0.0)l\"    \n",
       " \"t_float(4.398281802099419, 0.0)sqrt_llvm(4.3982818\"    \n",
       " \"02099419,)\"                                            "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod.(Xs[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ys = (map(t->occursin(\"sqrt_llvm\", prod(t)), text));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2479, 3000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Ys), length(Ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58Ã—50 Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}:\n",
       "  true  false  false  false  false  â€¦  false  false  false  false  false\n",
       " false   true  false  false  false     false  false  false  false  false\n",
       " false  false   true  false  false     false  false  false  false  false\n",
       " false  false  false   true  false     false  false  false  false  false\n",
       " false  false  false  false   true     false  false  false  false  false\n",
       " false  false  false  false  false  â€¦  false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false  â€¦  false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false      true  false  false  false  false\n",
       "     â‹®                              â‹±      â‹®                            \n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false  â€¦  false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false  â€¦  false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs_vec = [[onehotbatch(x, alphabet) for x in Xs[i]] for i in 1:length(Xs)];\n",
    "Xs_vec[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000-element Array{Int64,1}:\n",
       " 72500\n",
       " 72500\n",
       " 72500\n",
       " 72500\n",
       " 72500\n",
       " 72500\n",
       " 72500\n",
       " 72500\n",
       " 72500\n",
       " 72500\n",
       " 72500\n",
       " 72500\n",
       " 72500\n",
       "     â‹®\n",
       " 72500\n",
       " 72500\n",
       " 72500\n",
       " 72500\n",
       " 72500\n",
       " 72500\n",
       " 72500\n",
       " 72500\n",
       " 72500\n",
       " 72500\n",
       " 72500\n",
       " 72500"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ys = readdlm(\"y_results.csv\");\n",
    "labelset = unique(Ys)\n",
    "#dataset = [(onehotbatch(x, alphabet, '\\n'), onehot(Ys[i],labelset))\n",
    "#           for i in 1:length(Ys) for x in Xs[i]] |> shuffle\n",
    "dataset = shuffle([(Xs_vec[i], onehot(Ys[i], labelset)) for i in 1:length(Xs_vec)])\n",
    "Ys = last.(dataset)\n",
    "\n",
    "# Pad sequences to equal lengths\n",
    "#Xs_padded = [hcat(x,repeat(stop,1,seq_len-size(x)[1])) for x in first.(dataset)]\n",
    "Xs_padded = [hcat(x[1:25]...) for x in first.(dataset)]\n",
    "map(length, Xs_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 972,290 items in our data. We use a train:test split of 90:10, stratified to ensure we have \n",
    "# the same share of \"bad\" and \"good\" traces in our train and test sets.\n",
    "\n",
    "(Xtrain, Ytrain), (Xtest, Ytest) = stratifiedobs((Xs_padded, Ys), p=0.9)\n",
    "\n",
    "train = [(Xtrain[i], Ytrain[i]) for i in 1:length(Ytrain)];\n",
    "test = [(Xtest[i], Ytest[i]) for i in 1:length(Ytest)];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58Ã—1250 Array{Bool,2}:\n",
       "  true  false  false  false  false  â€¦  false  false  false  false  false\n",
       " false   true  false  false  false     false  false  false  false  false\n",
       " false  false   true  false  false     false  false  false  false  false\n",
       " false  false  false   true  false     false  false  false  false  false\n",
       " false  false  false  false   true     false  false  false  false  false\n",
       " false  false  false  false  false  â€¦  false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false      true  false  false  false   true\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false  â€¦  false  false  false  false  false\n",
       " false  false  false  false  false     false  false   true  false  false\n",
       " false  false  false  false  false     false  false  false   true  false\n",
       "     â‹®                              â‹±      â‹®                            \n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false  â€¦  false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false  â€¦  false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params([Float32[0.092204 0.12312 â€¦ -0.0509083 0.141771; -0.154509 -0.0309254 â€¦ -0.146467 -0.114301; â€¦ ; 0.229347 -0.216933 â€¦ 0.152333 0.0923766; -0.0323819 0.235028 â€¦ 0.196169 -0.203647] (tracked), Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  â€¦  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (tracked), Float32[-0.00201754 0.0422538 â€¦ -0.0476042 0.0998157; -0.03872 0.0183181 â€¦ -0.121725 0.0561775; â€¦ ; -0.000976615 -0.00398163 â€¦ -0.0539271 -0.0958087; 0.0658745 -0.128838 â€¦ -0.0471692 0.118311] (tracked), Float32[-0.00880199 0.094397 â€¦ 0.132086 -0.106352; 0.113541 -0.147772 â€¦ -0.0814755 -0.0401412; â€¦ ; 0.0469816 -0.15177 â€¦ -0.0944487 -0.151429; -0.0274256 -0.153434 â€¦ 0.0438874 0.0299447] (tracked), Float32[-0.114926, 0.148934, 0.047811, 0.0609061, 0.137653, 0.0148457, 0.0898842, 0.0250348, -0.106333, -0.0821758  â€¦  0.0843505, 0.133302, 0.0510322, 0.0745461, -0.136328, -0.0389513, -0.0623016, -0.0483884, -0.0873799, 0.167702] (tracked), Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  â€¦  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (tracked), Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  â€¦  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (tracked), Float32[0.188985 0.268387 â€¦ -0.32175 0.0625373; -0.160757 -0.137799 â€¦ 0.19416 -0.199044] (tracked), Float32[0.0, 0.0] (tracked)])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We set up our model architecture\n",
    "\n",
    "scanner = Chain(Dense(length(alphabet), seq_len, Ïƒ), LSTM(seq_len, seq_len))\n",
    "encoder = Dense(seq_len, 2)\n",
    "\n",
    "function model(x)\n",
    "  state = scanner.([x])[end]\n",
    "  Flux.reset!(scanner)\n",
    "  softmax(encoder(state))\n",
    "end\n",
    "\n",
    "loss(tup...) = begin\n",
    "    #@show typeof.(tup)\n",
    "    #@show size.(tup)\n",
    "    crossentropy(model(tup[1]), tup[2])\n",
    "end\n",
    "accuracy(tup...) = mean(argmax(model(tup[1])) .== argmax(tup[2]))\n",
    "\n",
    "opt = ADAM(0.000001)\n",
    "ps = params(scanner, encoder)\n",
    "#ps = params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#45 (generic function with 1 method)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, we set up our callbacks for reporting on training progress.\n",
    "mean(x) = sum(x)/length(x)\n",
    "#testacc() = mean(accuracy(t) for t in test)\n",
    "testloss() = mean(loss(t...) for t in test)\n",
    "\n",
    "evalcb = () -> @show testloss()#, testacc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testloss() = 781.3041f0 (tracked)\n",
      "testloss() = 776.22095f0 (tracked)\n",
      "testloss() = 772.70044f0 (tracked)\n",
      "testloss() = 768.3754f0 (tracked)\n",
      "testloss() = 763.0578f0 (tracked)\n",
      "testloss() = 758.77075f0 (tracked)\n",
      "testloss() = 753.8968f0 (tracked)\n",
      "testloss() = 748.3758f0 (tracked)\n",
      "testloss() = 744.4518f0 (tracked)\n",
      "testloss() = 738.4357f0 (tracked)\n"
     ]
    }
   ],
   "source": [
    "# Now, train!\n",
    "Flux.train!(loss, ps, train, opt, cb = throttle(evalcb, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params([Float32[0.0940121 0.124935 â€¦ -0.0509083 0.141771; -0.156174 -0.0326008 â€¦ -0.146467 -0.114301; â€¦ ; 0.227655 -0.218624 â€¦ 0.152333 0.0923766; -0.0340876 0.233315 â€¦ 0.196169 -0.203647] (tracked), Float32[0.00181466, -0.00167447, 0.00206472, 0.00261433, 0.00243351, 0.00178143, -0.0016603, -0.00173892, -0.00125623, 0.0017878  â€¦  -0.00171839, -0.00162966, 0.000603553, 0.00186516, 0.0018682, 0.001819, -0.00171817, -0.00153048, -0.00169567, -0.00171098] (tracked), Float32[-8.42247e-5 0.0441859 â€¦ -0.045672 0.101749; -0.0368795 0.0201577 â€¦ -0.119885 0.0580172; â€¦ ; 0.000853458 -0.00215264 â€¦ -0.0520977 -0.0939795; 0.0643062 -0.130405 â€¦ -0.0487364 0.116744] (tracked), Float32[-0.0115358 0.0971321 â€¦ 0.134828 -0.109086; 0.110875 -0.145105 â€¦ -0.0788017 -0.0428075; â€¦ ; 0.044323 -0.14911 â€¦ -0.0917821 -0.154088; -0.0249757 -0.155885 â€¦ 0.041429 0.0323947] (tracked), Float32[-0.112993, 0.150775, 0.0499197, 0.0626871, 0.139467, 0.0166777, 0.088253, 0.0233359, -0.104539, -0.0838754  â€¦  0.0826611, 0.131595, 0.0493573, 0.0764708, -0.134502, -0.0369624, -0.06393, -0.0500775, -0.0855504, 0.166134] (tracked), Float32[-0.0017989, 0.00180843, 0.00186852, -0.0019831, 0.00184282, -0.00184604, -0.00182692, 0.00204716, 0.00184116, -0.00185172  â€¦  -0.00182481, 0.00180995, 0.00182237, 0.00185765, -0.00186994, -0.00181873, -0.00193066, -0.00182378, 0.00186127, -0.00180015] (tracked), Float32[0.00178532, 0.00177542, -0.00178627, -0.00177346, 0.00178047, -0.00181644, 0.0017626, -0.00175013, -0.00177486, 0.00175476  â€¦  0.00175997, 0.00175781, -0.00172917, -0.00178627, 0.00177745, -0.00178862, 0.00175105, 0.00176275, -0.00177511, 0.00175895] (tracked), Float32[0.190928 0.270236 â€¦ -0.323585 0.0609741; -0.1627 -0.139648 â€¦ 0.195995 -0.197481] (tracked), Float32[0.00176234, -0.00176234] (tracked)])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.(Xs_padded)[:,end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t1.471\t0.51874804f0 (tracked)\n",
      "1\t1.462\t0.5211691f0 (tracked)\n",
      "1\t1.455\t0.5230118f0 (tracked)\n",
      "1\t1.456\t0.5227492f0 (tracked)\n",
      "1\t1.496\t0.5118083f0 (tracked)\n",
      "2\t1.476\t0.9068327f0 (tracked)\n",
      "2\t1.452\t0.89673f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "1\t1.456\t0.5227492f0 (tracked)\n",
      "1\t1.462\t0.5211691f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "1\t1.456\t0.5228054f0 (tracked)\n",
      "1\t1.456\t0.5227492f0 (tracked)\n",
      "1\t1.451\t0.5243726f0 (tracked)\n",
      "1\t1.471\t0.51874804f0 (tracked)\n",
      "2\t1.462\t0.90112954f0 (tracked)\n",
      "1\t1.456\t0.5227492f0 (tracked)\n",
      "1\t1.455\t0.5230118f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "1\t1.469\t0.51913625f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "1\t1.451\t0.5243726f0 (tracked)\n",
      "1\t1.461\t0.52153325f0 (tracked)\n",
      "1\t1.469\t0.51913625f0 (tracked)\n",
      "1\t1.462\t0.5211691f0 (tracked)\n",
      "1\t1.446\t0.5255746f0 (tracked)\n",
      "1\t1.44\t0.527337f0 (tracked)\n",
      "1\t1.455\t0.5230118f0 (tracked)\n",
      "1\t1.496\t0.5118083f0 (tracked)\n",
      "1\t1.461\t0.52153325f0 (tracked)\n",
      "2\t1.462\t0.9010203f0 (tracked)\n",
      "1\t1.46\t0.52179074f0 (tracked)\n",
      "2\t1.448\t0.8954526f0 (tracked)\n",
      "2\t1.442\t0.89300734f0 (tracked)\n",
      "2\t1.452\t0.89673f0 (tracked)\n",
      "1\t1.465\t0.5202537f0 (tracked)\n",
      "1\t1.465\t0.5202537f0 (tracked)\n",
      "1\t1.446\t0.5257667f0 (tracked)\n",
      "1\t1.448\t0.52496284f0 (tracked)\n",
      "1\t1.463\t0.52091664f0 (tracked)\n",
      "1\t1.457\t0.5224655f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "1\t1.465\t0.5202537f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "1\t1.465\t0.5202537f0 (tracked)\n",
      "1\t1.455\t0.5230118f0 (tracked)\n",
      "1\t1.471\t0.51874804f0 (tracked)\n",
      "1\t1.471\t0.51874804f0 (tracked)\n",
      "2\t1.462\t0.9010203f0 (tracked)\n",
      "1\t1.458\t0.522217f0 (tracked)\n",
      "1\t1.446\t0.5255746f0 (tracked)\n",
      "2\t1.465\t0.9023132f0 (tracked)\n",
      "2\t1.476\t0.9068327f0 (tracked)\n",
      "1\t1.471\t0.51874804f0 (tracked)\n",
      "1\t1.493\t0.51280224f0 (tracked)\n",
      "1\t1.469\t0.51913625f0 (tracked)\n",
      "1\t1.458\t0.522217f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "1\t1.471\t0.51874804f0 (tracked)\n",
      "1\t1.457\t0.5224655f0 (tracked)\n",
      "1\t1.456\t0.5228054f0 (tracked)\n",
      "1\t1.46\t0.52179074f0 (tracked)\n",
      "1\t1.476\t0.5171811f0 (tracked)\n",
      "1\t1.471\t0.51874804f0 (tracked)\n",
      "1\t1.462\t0.5211691f0 (tracked)\n",
      "1\t1.485\t0.5149421f0 (tracked)\n",
      "1\t1.451\t0.5243726f0 (tracked)\n",
      "1\t1.464\t0.52069336f0 (tracked)\n",
      "1\t1.471\t0.51874804f0 (tracked)\n",
      "1\t1.456\t0.5227492f0 (tracked)\n",
      "1\t1.46\t0.52179074f0 (tracked)\n",
      "2\t1.465\t0.9023132f0 (tracked)\n",
      "2\t1.462\t0.9009733f0 (tracked)\n",
      "1\t1.465\t0.5202537f0 (tracked)\n",
      "1\t1.462\t0.52113694f0 (tracked)\n",
      "1\t1.455\t0.5230118f0 (tracked)\n",
      "1\t1.455\t0.5230118f0 (tracked)\n",
      "1\t1.465\t0.5202537f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "1\t1.446\t0.5257283f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "1\t1.446\t0.5257352f0 (tracked)\n",
      "1\t1.446\t0.5255746f0 (tracked)\n",
      "1\t1.451\t0.5243726f0 (tracked)\n",
      "2\t1.46\t0.90006536f0 (tracked)\n",
      "1\t1.453\t0.5236768f0 (tracked)\n",
      "1\t1.458\t0.522217f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "1\t1.464\t0.52069336f0 (tracked)\n",
      "1\t1.493\t0.51280224f0 (tracked)\n",
      "1\t1.458\t0.522217f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "2\t1.485\t0.91014755f0 (tracked)\n",
      "1\t1.481\t0.5158362f0 (tracked)\n",
      "1\t1.458\t0.522217f0 (tracked)\n",
      "1\t1.481\t0.5158362f0 (tracked)\n",
      "1\t1.465\t0.5202537f0 (tracked)\n",
      "1\t1.448\t0.52496284f0 (tracked)\n",
      "1\t1.46\t0.52179074f0 (tracked)\n",
      "1\t1.464\t0.52069336f0 (tracked)\n",
      "1\t1.46\t0.52179074f0 (tracked)\n",
      "2\t1.448\t0.8954526f0 (tracked)\n",
      "2\t1.493\t0.9133331f0 (tracked)\n",
      "1\t1.46\t0.5217651f0 (tracked)\n",
      "1\t1.469\t0.51913625f0 (tracked)\n",
      "1\t1.462\t0.52113694f0 (tracked)\n",
      "1\t1.465\t0.5202537f0 (tracked)\n",
      "1\t1.452\t0.52391726f0 (tracked)\n",
      "1\t1.493\t0.51280224f0 (tracked)\n",
      "1\t1.455\t0.5230118f0 (tracked)\n",
      "1\t1.471\t0.51874804f0 (tracked)\n",
      "1\t1.465\t0.5202537f0 (tracked)\n",
      "2\t1.455\t0.8982856f0 (tracked)\n",
      "1\t1.461\t0.52153325f0 (tracked)\n",
      "1\t1.46\t0.52179074f0 (tracked)\n",
      "1\t1.463\t0.52091664f0 (tracked)\n",
      "1\t1.458\t0.522217f0 (tracked)\n",
      "1\t1.456\t0.5227492f0 (tracked)\n",
      "1\t1.461\t0.52153325f0 (tracked)\n",
      "1\t1.493\t0.51280224f0 (tracked)\n",
      "1\t1.458\t0.522217f0 (tracked)\n",
      "1\t1.462\t0.5211691f0 (tracked)\n",
      "1\t1.493\t0.51280224f0 (tracked)\n",
      "1\t1.476\t0.5171811f0 (tracked)\n",
      "1\t1.457\t0.5224655f0 (tracked)\n",
      "1\t1.462\t0.52113694f0 (tracked)\n",
      "1\t1.44\t0.527337f0 (tracked)\n",
      "2\t1.471\t0.9045236f0 (tracked)\n",
      "1\t1.472\t0.51838034f0 (tracked)\n",
      "1\t1.46\t0.52179074f0 (tracked)\n",
      "2\t1.46\t0.90006536f0 (tracked)\n",
      "1\t1.462\t0.52113694f0 (tracked)\n",
      "1\t1.455\t0.5230118f0 (tracked)\n",
      "1\t1.456\t0.5227492f0 (tracked)\n",
      "1\t1.471\t0.51874804f0 (tracked)\n",
      "1\t1.472\t0.5184305f0 (tracked)\n",
      "2\t1.476\t0.9068327f0 (tracked)\n",
      "1\t1.462\t0.5211691f0 (tracked)\n",
      "1\t1.453\t0.5236768f0 (tracked)\n",
      "1\t1.476\t0.5171811f0 (tracked)\n",
      "1\t1.476\t0.5171811f0 (tracked)\n",
      "1\t1.455\t0.5230118f0 (tracked)\n",
      "2\t1.458\t0.8994433f0 (tracked)\n",
      "2\t1.446\t0.894335f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "1\t1.448\t0.52496284f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "1\t1.451\t0.5243726f0 (tracked)\n",
      "1\t1.448\t0.52496284f0 (tracked)\n",
      "2\t1.446\t0.89428955f0 (tracked)\n",
      "2\t1.452\t0.89673f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "2\t1.44\t0.8920238f0 (tracked)\n",
      "1\t1.465\t0.5202537f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "1\t1.442\t0.52665466f0 (tracked)\n",
      "2\t1.463\t0.90134263f0 (tracked)\n",
      "1\t1.453\t0.5236768f0 (tracked)\n",
      "1\t1.458\t0.522217f0 (tracked)\n",
      "1\t1.448\t0.52496284f0 (tracked)\n",
      "2\t1.458\t0.8994433f0 (tracked)\n",
      "1\t1.446\t0.5257667f0 (tracked)\n",
      "1\t1.451\t0.5243726f0 (tracked)\n",
      "1\t1.493\t0.51280224f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "1\t1.448\t0.52496284f0 (tracked)\n",
      "1\t1.455\t0.5230118f0 (tracked)\n",
      "1\t1.472\t0.5184305f0 (tracked)\n",
      "1\t1.472\t0.5184305f0 (tracked)\n",
      "1\t1.493\t0.51280224f0 (tracked)\n",
      "1\t1.442\t0.52665466f0 (tracked)\n",
      "2\t1.462\t0.90112954f0 (tracked)\n",
      "1\t1.458\t0.522217f0 (tracked)\n",
      "2\t1.451\t0.89630824f0 (tracked)\n",
      "1\t1.44\t0.527337f0 (tracked)\n",
      "1\t1.476\t0.5171811f0 (tracked)\n",
      "1\t1.462\t0.5211691f0 (tracked)\n",
      "2\t1.462\t0.9009733f0 (tracked)\n",
      "1\t1.455\t0.5230118f0 (tracked)\n",
      "2\t1.448\t0.8954526f0 (tracked)\n",
      "1\t1.469\t0.51913625f0 (tracked)\n",
      "2\t1.456\t0.898668f0 (tracked)\n",
      "1\t1.462\t0.5211691f0 (tracked)\n",
      "1\t1.453\t0.5236768f0 (tracked)\n",
      "1\t1.461\t0.52153325f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "1\t1.465\t0.5202537f0 (tracked)\n",
      "1\t1.471\t0.51874804f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "2\t1.446\t0.89428955f0 (tracked)\n",
      "2\t1.472\t0.90506464f0 (tracked)\n",
      "1\t1.469\t0.51913625f0 (tracked)\n",
      "1\t1.481\t0.5158362f0 (tracked)\n",
      "2\t1.46\t0.90006536f0 (tracked)\n",
      "2\t1.452\t0.89696914f0 (tracked)\n",
      "1\t1.462\t0.5211691f0 (tracked)\n",
      "2\t1.469\t0.90395296f0 (tracked)\n",
      "1\t1.463\t0.52091664f0 (tracked)\n",
      "2\t1.462\t0.9009733f0 (tracked)\n",
      "1\t1.46\t0.52179074f0 (tracked)\n",
      "1\t1.464\t0.52069336f0 (tracked)\n",
      "1\t1.46\t0.5216048f0 (tracked)\n",
      "1\t1.469\t0.51913625f0 (tracked)\n",
      "1\t1.46\t0.52179074f0 (tracked)\n",
      "1\t1.446\t0.5257667f0 (tracked)\n",
      "1\t1.455\t0.5230118f0 (tracked)\n",
      "1\t1.44\t0.527337f0 (tracked)\n",
      "1\t1.462\t0.5211691f0 (tracked)\n",
      "1\t1.46\t0.52179074f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "1\t1.452\t0.52391726f0 (tracked)\n",
      "2\t1.455\t0.8982856f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "2\t1.457\t0.89908105f0 (tracked)\n",
      "1\t1.458\t0.522217f0 (tracked)\n",
      "1\t1.46\t0.5216048f0 (tracked)\n",
      "2\t1.455\t0.8982856f0 (tracked)\n",
      "1\t1.462\t0.5211691f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "1\t1.44\t0.527337f0 (tracked)\n",
      "1\t1.469\t0.51913625f0 (tracked)\n",
      "1\t1.476\t0.5171811f0 (tracked)\n",
      "1\t1.462\t0.5211691f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "1\t1.472\t0.5184305f0 (tracked)\n",
      "1\t1.469\t0.51913625f0 (tracked)\n",
      "2\t1.446\t0.8945673f0 (tracked)\n",
      "1\t1.455\t0.5230118f0 (tracked)\n",
      "1\t1.462\t0.5211691f0 (tracked)\n",
      "1\t1.462\t0.5211691f0 (tracked)\n",
      "2\t1.461\t0.90044117f0 (tracked)\n",
      "1\t1.46\t0.5217651f0 (tracked)\n",
      "1\t1.465\t0.5202537f0 (tracked)\n",
      "1\t1.446\t0.5257352f0 (tracked)\n",
      "2\t1.458\t0.8994433f0 (tracked)\n",
      "2\t1.452\t0.89673f0 (tracked)\n",
      "2\t1.461\t0.90046835f0 (tracked)\n",
      "2\t1.448\t0.8954526f0 (tracked)\n",
      "1\t1.471\t0.51874804f0 (tracked)\n",
      "1\t1.471\t0.51874804f0 (tracked)\n",
      "1\t1.462\t0.52113694f0 (tracked)\n",
      "1\t1.44\t0.527337f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "1\t1.456\t0.5228054f0 (tracked)\n",
      "1\t1.446\t0.5257283f0 (tracked)\n",
      "1\t1.448\t0.52496284f0 (tracked)\n",
      "1\t1.462\t0.5211691f0 (tracked)\n",
      "2\t1.462\t0.9009733f0 (tracked)\n",
      "1\t1.46\t0.5217651f0 (tracked)\n",
      "1\t1.46\t0.52179074f0 (tracked)\n",
      "1\t1.446\t0.5257352f0 (tracked)\n",
      "1\t1.493\t0.51280224f0 (tracked)\n",
      "1\t1.452\t0.52391726f0 (tracked)\n",
      "2\t1.472\t0.90506464f0 (tracked)\n",
      "1\t1.446\t0.5255746f0 (tracked)\n",
      "1\t1.452\t0.52391726f0 (tracked)\n",
      "1\t1.457\t0.5224655f0 (tracked)\n",
      "2\t1.472\t0.9049908f0 (tracked)\n",
      "1\t1.46\t0.52179074f0 (tracked)\n",
      "2\t1.44\t0.8920238f0 (tracked)\n",
      "2\t1.46\t0.90006536f0 (tracked)\n",
      "1\t1.455\t0.5230118f0 (tracked)\n",
      "1\t1.456\t0.5228054f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "1\t1.46\t0.5216048f0 (tracked)\n",
      "1\t1.452\t0.52391726f0 (tracked)\n",
      "1\t1.464\t0.52069336f0 (tracked)\n",
      "2\t1.452\t0.89673f0 (tracked)\n",
      "1\t1.462\t0.5211691f0 (tracked)\n",
      "1\t1.44\t0.527337f0 (tracked)\n",
      "2\t1.46\t0.90006536f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "2\t1.472\t0.90506464f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "1\t1.456\t0.5227492f0 (tracked)\n",
      "1\t1.471\t0.51874804f0 (tracked)\n",
      "1\t1.496\t0.5118083f0 (tracked)\n",
      "1\t1.455\t0.5230118f0 (tracked)\n",
      "1\t1.472\t0.51838034f0 (tracked)\n",
      "1\t1.471\t0.51874804f0 (tracked)\n",
      "1\t1.452\t0.5240819f0 (tracked)\n",
      "1\t1.46\t0.52179074f0 (tracked)\n",
      "2\t1.471\t0.9045236f0 (tracked)\n",
      "1\t1.456\t0.5227492f0 (tracked)\n",
      "1\t1.452\t0.52391726f0 (tracked)\n",
      "1\t1.456\t0.5227492f0 (tracked)\n",
      "1\t1.455\t0.5230118f0 (tracked)\n",
      "2\t1.463\t0.90134263f0 (tracked)\n",
      "1\t1.469\t0.51913625f0 (tracked)\n",
      "1\t1.481\t0.5158362f0 (tracked)\n",
      "1\t1.463\t0.52091664f0 (tracked)\n",
      "1\t1.448\t0.52496284f0 (tracked)\n",
      "2\t1.458\t0.8994433f0 (tracked)\n",
      "1\t1.472\t0.5184305f0 (tracked)\n",
      "1\t1.46\t0.52179074f0 (tracked)\n",
      "1\t1.458\t0.522217f0 (tracked)\n",
      "1\t1.469\t0.51913625f0 (tracked)\n",
      "1\t1.46\t0.52179074f0 (tracked)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tracked 2-element Array{Float64,1}:\n",
       " 0.056582545202871655\n",
       " 0.11129543280550666 "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumÎ· = [0.0,0.0]\n",
    "for i in 1:300\n",
    "    yhat = model(train[i][1])[:,end]\n",
    "    Î· = crossentropy(yhat, train[i][2])\n",
    "    sumÎ· += Î·.*train[i][2]\n",
    "    Ï… = Flux.onecold(train[i][2])\n",
    "    logods = round(Flux.data(yhat[1]/yhat[2]);digits=3)\n",
    "    println(\"$Ï…\\t$logods\\t$Î·\")\n",
    "end\n",
    "Î·bar = sumÎ·./sum(train[i][2] for i in 1:length(train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000-element Array{Tuple{},1}:\n",
       " ()\n",
       " ()\n",
       " ()\n",
       " ()\n",
       " ()\n",
       " ()\n",
       " ()\n",
       " ()\n",
       " ()\n",
       " ()\n",
       " ()\n",
       " ()\n",
       " ()\n",
       " â‹® \n",
       " ()\n",
       " ()\n",
       " ()\n",
       " ()\n",
       " ()\n",
       " ()\n",
       " ()\n",
       " ()\n",
       " ()\n",
       " ()\n",
       " ()\n",
       " ()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(x->size(x[end]), Xs_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58Ã—1500 Array{Bool,2}:\n",
       "  true  false  false  false  false  â€¦  false  false  false  false  false\n",
       " false   true  false  false  false     false  false  false  false  false\n",
       " false  false   true  false  false     false  false  false  false  false\n",
       " false  false  false   true  false     false  false  false  false  false\n",
       " false  false  false  false   true     false  false  false  false  false\n",
       " false  false  false  false  false  â€¦  false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false  â€¦  false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       "     â‹®                              â‹±      â‹®                            \n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false   true  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false  â€¦  false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false  â€¦  false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false\n",
       " false  false  false  false  false     false  false  false  false  false"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
